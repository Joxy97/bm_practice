# Boltzmann Machine Sampler Benchmark Configuration
#
# This configuration is specifically for benchmarking different sampling methods
# by computing KL divergence between empirical distributions from samplers
# and the exact Boltzmann distribution.
#
# Usage:
#   python main.py --mode benchmark --config benchmark_configs/config_benchmark.yaml

# Random seed for reproducibility
seed: 42

# Device configuration
device:
  use_cuda: "auto"  # "auto", "cuda", or "cpu"

# Benchmark Configuration
benchmark:
  # === Samplers to Benchmark ===
  # List of samplers to test. Each sampler will be evaluated across all problem sizes.
  #
  # ===== RECOMMENDED PRODUCTION SAMPLERS =====
  # MCMC Samplers (unbiased, proper sampling from distribution):
  #   "gibbs"                     - BEST for BM training, theoretically correct
  #   "gibbs_gpu"                 - GPU version for large-scale (N>1000)
  #   "metropolis"                - Alternative MCMC sampler
  #   "metropolis_gpu"            - GPU version for high throughput
  #   "parallel_tempering"        - For complex/multimodal energy landscapes
  #   "parallel_tempering_gpu"    - GPU version with vectorized ΔE
  #
  # ===== EXACT SAMPLERS (Ground Truth, N ≤ 20 only) =====
  #   "exact"                     - Brute force enumeration (perfect benchmark)
  #   "gumbel_max"                - Independent exact samples via Gumbel-max
  #
  # ===== OPTIMIZERS (Not proper samplers, biased toward low energy) =====
  # These are OPTIMIZATION TOOLS, not samplers for training! Use them for finding ground states, not for BM training:
  #   "simulated_annealing"       - Temperature annealing optimizer
  #   "simulated_annealing_gpu"   - GPU version
  #   "population_annealing_gpu"  - Population-based optimizer
  #   "tabu"                      - Tabu search metaheuristic
  #   "steepest_descent"          - Local search hill climbing
  #   "greedy"                    - Greedy heuristic
  #
  # ===== BASELINE =====
  #   "random"                    - Uniform random (baseline for comparison)
  #
  # ===== QUANTUM (Requires D-Wave Leap Account) =====
  #   "dwave"                  - D-Wave quantum annealer (QPU)
  #   "advantage"              - D-Wave Advantage system (alias)
  samplers:
    - "gibbs"
    - "gibbs_gpu"
    - "metropolis"
    - "metropolis_gpu"
    - "parallel_tempering"
    - "parallel_tempering_gpu"

  # === Problem Sizes ===
  # Range of problem sizes (number of variables) to test.
  # Computational complexity grows as O(2^N) for exact distribution computation.
  # Recommended: Keep N ≤ 20 for exact computations, N ≤ 10 for practical benchmarking.
  n_variables_range: [2, 3, 4, 5, 6, 7, 8, 9, 10]

  # === Sampling Configuration ===
  # Number of samples to generate per benchmark run.
  # Higher values give better empirical distribution estimates but take longer.
  n_samples: 1000

  # === True Model Parameters ===
  # Configuration for the random Boltzmann Machines used in benchmarking.
  # Each benchmark run creates a new random FVBM with these settings.
  model_type: "fvbm"            # Always use fully visible BM for benchmarking
  connectivity: "dense"         # Always use dense connectivity
  linear_bias_scale: 1.0        # Scale for random linear biases
  quadratic_weight_scale: 1.5   # Scale for random quadratic weights

  # === Metrics Configuration ===
  # Configure which metrics to compute during benchmarking
  metrics:
    # List of enabled metrics
    enabled:
      - "kl_divergence"           # Forward KL: D_KL(p_true || p_empirical)
      - "reverse_kl_divergence"   # Reverse KL: D_KL(p_empirical || p_true)
      - "total_variation"         # Total Variation Distance
      - "mmd"                     # Maximum Mean Discrepancy
      - "moment_matching"         # First and second moment matching error

    # MMD kernel configuration
    mmd_kernel: "rbf_hamming"     # "rbf_hamming" or "linear_hamming"
    mmd_kernel_bandwidth: 1.0     # Bandwidth for RBF kernel

  # === Sampler-Specific Parameters ===
  # Default parameters used for all samplers during benchmarking.
  # These can be overridden per-sampler if needed.
  sampler_params:
    # Common parameters:
    num_reads: 1000  # Number of samples to request (will be capped to n_samples)

    # ===== MCMC SAMPLER PARAMETERS =====

    # Gibbs sampler parameters:
    num_sweeps: 1000         # Number of MCMC sweeps
    burn_in: 100             # Burn-in period
    thinning: 1              # Keep every nth sample
    randomize_order: true    # Randomize variable update order

    # Gibbs GPU parameters (additional):
    num_chains: 32           # Number of parallel chains (default: 32)
    use_cuda: true           # Use CUDA if available (default: true)

    # Metropolis sampler parameters:
    temperature: 1.0         # Temperature T for acceptance probability (default: 1.0)
    num_sweeps: 1000         # Number of MCMC sweeps (default: 1000)
    burn_in: 100             # Burn-in period (default: 100)
    thinning: 1              # Keep every nth sample (default: 1)

    # Metropolis GPU parameters (additional):
    num_chains: 32           # Number of parallel chains (default: 32)
    use_cuda: true           # Use CUDA if available (default: true)

    # Parallel Tempering parameters:
    num_replicas: 8          # Number of temperature replicas (default: 8)
    T_min: 1.0               # Minimum temperature (default: 1.0)
    T_max: 4.0               # Maximum temperature (default: 4.0)
    swap_interval: 10        # Sweeps between swap attempts (default: 10)
    num_sweeps: 1000         # Total number of sweeps (default: 1000)
    burn_in: 100             # Burn-in period (default: 100)
    thinning: 1              # Keep every nth sample (default: 1)

    # ===== EXACT SAMPLER PARAMETERS =====

    # Exact sampler parameters:
    # max_variables: 20        # Maximum number of variables (N <= 20, default: 20)

    # Gumbel-max sampler parameters:
    # max_variables: 20        # Maximum number of variables (N <= 20, default: 20)

    # ===== OPTIMIZER PARAMETERS (Not for proper sampling) =====

    # Simulated Annealing parameters (OPTIMIZER, not proper sampler):
    # beta_range: [1.0, 10.0]                   # Inverse temperature schedule
    # proposal_acceptance_criteria: "Metropolis" # "Gibbs" or "Metropolis"
    # num_sweeps: 1000         # Number of sweeps

    # Simulated Annealing GPU parameters (additional):
    # num_chains: 32           # Number of parallel annealing chains
    # use_cuda: true           # Use CUDA if available

    # Population Annealing GPU parameters (OPTIMIZER):
    # population_size: 1000    # Size of parallel population
    # num_sweeps: 100          # Number of temperature steps
    # beta_min: 0.1            # Initial inverse temperature
    # beta_max: 10.0           # Final inverse temperature
    # resample_threshold: 0.5  # Resample when ESS < threshold * population_size
    # use_cuda: true           # Use CUDA if available

    # Tabu sampler parameters (OPTIMIZER):
    tenure: null             # Tabu list size (default: auto)
    timeout: 20              # Timeout in seconds

    # ===== QUANTUM SAMPLER PARAMETERS =====

    # D-Wave quantum/hybrid parameters:
    # solver: null             # Optional: specify solver name
    # time_limit: 5            # For hybrid samplers (seconds)

# Data/Model Generation (for compatibility with run_manager)
# This section is only used for prefactor value during sampling.
# The actual models are created dynamically by the benchmark suite.
data_generation:
  prefactor: 1.0  # Energy scaling factor

# Logging and Visualization
logging:
  log_interval: 1         # Log interval (not used in benchmarking)
  save_plots: true        # Save visualization plots
  plot_dir: "outputs/plots"

# Output Paths
paths:
  data_dir: "outputs/data"      # Where benchmark_results.csv and benchmark_summary.csv are saved
  model_dir: "outputs/models"   # Not used in benchmarking
  log_dir: "outputs/logs"       # Not used in benchmarking
